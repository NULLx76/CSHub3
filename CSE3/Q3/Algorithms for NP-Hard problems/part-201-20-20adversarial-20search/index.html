<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>MyBlog</title>
  <link rel="stylesheet" href="https://nullx76.github.io/CSHub3/main.css">
</head>

<body>
  <div class="container">
    <head>
      <h1><a href="/">CSHub.nl</a></h1>
    </head>
    <section class="section">
      
  <section class="page">
  <h1 id="adversarial-search">Adversarial Search</h1><p>So far we have discussed search algorithms where only 1 agent is  active. Now we introduce an opponent (adversarial), which works against our agent (e.g. in Tic-Tac-Toe) to try and achieve the opposite goal.</p><p><br></p><h2 id="minimax-search">Minimax search</h2><p>For these deterministic games with two players, minimax search works very well. In minimax, we try to maximimze the score of the MAX player, and minimize the score of the MIN player.</p><p><br></p><p>An easy way to do this is graphing all possible ways a game can go, and assign a value to each outcome.</p><p><img src="https://i.imgur.com/a9V5v0N.png" width="498"></p><p><br></p><p>Note that we play value-maximizing moves, assuming that the adversary plays value-minimizing moves. </p><p>This we do by computing the minimax scores of all its children and we pick the node that will lead to the maximum score.</p><p><br></p><h3 id="definitions">Definitions</h3><p>In minimax, we define the following:</p><div style="white-space: normal;" class="markdown-body"><ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">S_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>: initial state</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>PLAYER</mtext><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{PLAYER}(s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">PLAYER</span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span></span></span></span>: which player to move in state <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">s</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>ACTIONS</mtext><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{ACTIONS}(s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">ACTIONS</span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span></span></span></span>: the legal moves in state <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">s</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>RESULT</mtext><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{RESULT}(s,a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">RESULT</span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mclose">)</span></span></span></span>: the state after action <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span> was taken in state <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">s</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>TERMINAL</mtext><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{TERMINAL}(s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">TERMINAL</span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span></span></span></span>: if state <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">s</span></span></span></span> is a terminal state</li>
</ul>
</div><p><br></p><h2 id="improving-upon-minimax">Improving upon minimax</h2><p>However, this approach will work pretty poor if we are dealing with more complex games, since the tree would become too big.</p><p><br></p><p>A few possible approaches to improve it:</p><p><br></p><h3 id="depth-limiting">Depth limiting</h3><p>An option is to not explore the entire tree, but only a certain maximum depth. This reduces the total amount of options a lot, but it can also lose a lot of information.</p><p><br></p><h3 id="alpha-beta-pruning">Alpha-beta pruning</h3><p>When we use alpha-beta pruning, it stops evaluating a move when at least one possibility has been found that proves the move to be worse than a previously examined move.</p><p><br></p><p>This means that we don't need to evaluate the rest of the options in the <span class="ql-formula" data-value="\le3">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>≤</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">\le3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.7719400000000001em; vertical-align: -0.13597em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right: 0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">3</span></span></span></span></span>﻿</span> subtree:</p><p><img src="https://i.imgur.com/4bnaHly.png" width="479"></p><p><br></p><p>We can prune effectively by:</p><ul><li>Ordering the nodes well (high to low when maximizing, low to high when minimizing)</li><li>Re-use previous (partial) searches of the tree</li><li>Using a good heuristic evaluation function</li><li class="ql-indent-1">This can be done using efficient neural networks</li></ul><p><br></p><h3 id="search-stochastically">Search stochastically</h3><p>This will be discussed in part 2 of the course.</p><p><br></p><p><br></p>
  </section>

    </section>
  </div>
</body>

</html>