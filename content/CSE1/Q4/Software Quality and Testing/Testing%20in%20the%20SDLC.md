+++
title = "Testing in the SDLC"
date = 2019-09-29
+++
<h2 id="iterative-life-cycles">Iterative life cycles</h2><p>The software life cycle is a period of time that begins when a software system is conceived and ends when the system is no longer available for use. This cycle contains different phases which may overlap and be performed iteratively. A common feature of iterative approaches is that the delivery is divided into increments or builds with each increment adding new functionality. These subsequent increments will only need testing for the new functionality (regression). </p><p><br></p><h2 id="test-levels">Test levels</h2><p>These test levels can be seen as a testing pyramid. The further up the pyramid, the better the tests but the more time it takes to write/execute. In reality, a lot of people use an anti-pattern, which costs a lot more time. This is visualized here:</p><p><img src="https://i.imgur.com/NkQ1Qpi.png" width="574"></p><p><em>Image taken from slides by Mauricio Aniche</em></p><p><br></p><h3 id="component-(unit)-testing"><strong>Component</strong> (unit) <strong>testing</strong></h3><p>Testing smaller units in isolation. Here <strong>stubs</strong> (called from the to be tested component) and <strong>drivers </strong>(calls the component to be tested) are used to replace the missing software. Component testing may also include non-functional characteristics (testing for memory leaks etc). All business rules should be tested here.</p><p><br></p><h3 id="integration-testing"><strong>Integration testing</strong></h3><p>Testing interaction between units with other parts of the system such as an operating system or other systems. This integration testing is often carried out by the integrator. There are multiple levels in integration:</p><ul><li>Component integration testing tests the interactions between software components and is done after component testing</li><li>System integration testing tests the interactions between different systems and may be done after system testing</li></ul><p><br></p><p>The greater the scope of integration, the harder it is. Sometimes systems are just put in place and tested then ('big-bang' integration testing), but this makes it very time-consuming to trace cause of failures. It is also possible to do this incrementally, integrating a small part and adding more parts and testing them incrementally. There are multiple possibilities for that:</p><ul><li><strong>Top-down</strong>: testing takes place from top to bottom (e.g. start from GUI)</li><li><strong>Bottom-up</strong>: Starts at the bottom and looks up for what components use it and start testing that.</li><li><strong>Functional incremental: </strong>testing takes places on basis of functionality</li></ul><p><br></p><h3 id="system-testing"><strong>System testing</strong></h3><p>Testing system-level properties, mostly verification against requirements. This is carried out by specialist testers that form a dedicated, and sometimes independent, test team within development, reporting to the development manager or project manager. These tests may include functional and non-functional requirements of the system (e.g. performance and reliability). Such tests can be executed black-box (specification-based) or white-box (structure-based). Often, these tests are slow and non-deterministic (doesn't always give the same result).</p><p><br></p><h3 id="acceptance-testing"><strong>Acceptance testing</strong></h3><p>Testing focused on user's needs, finding defects should not be the main focus in acceptance testing. Acceptance testing is most often the responsibility of the user or customer, although other stakeholders may be involved as well. The <strong>user acceptance test</strong> focuses mainly on the functionality thereby validating the fitness-for-use of the system by the business user, while the <strong>operational acceptance test</strong> (also called production acceptance test) validates whether the system meets the requirements for operation. The operational acceptance test may include testing of backup/restore, disaster recovery, maintenance tasks and periodic checks for security vulnerabilities.</p><p><br></p><h3 id="maintenance-testing"><strong>Maintenance testing</strong></h3><p>Testing after a system is stable and deployed. Test changes to an operation system and test the impact of changed environments to an operational system. This usually consists of two parts: testing the changes and regression tests to show that the rest of the system wasn't affected by the maintenance.</p><p><br></p><p>There can be a few triggers for maintenance testing:</p><ul><li>Planned modifications, changes to the system that were planned beforehand</li><li>Ad-hoc corrective modifications, where immediate changes to the system was needed</li></ul><p><br></p><h2 id="test-types"><strong>Test types</strong></h2><h3 id="testing-of-function">Testing of function</h3><p>Functional testing tests whether the product does what it is supposed to do (also referred to as <strong>black-box testing</strong>). Function (or functionality) testing can, based upon ISO 9126, be done focusing on suitability, interoperability, security, accuracy and compliance. Testing functionality can be done from two perspectives:</p><ul><li>Requirements-based, using a specification of the functional requirements as a basis for designing tests</li><li>Business-process-based, using knowledge of the business process </li></ul><p><br></p><h3 id="testing-of-software-product-characteristics-(non-functional-testing)">Testing of software product characteristics (non-functional testing)</h3><p>Here we are interested in how well or how fast something is done. This type of testing includes performance testing, load testing, stress testing etc. The characteristics used are:</p><ul><li>Reliability</li><li>Usability</li><li>Efficiency</li><li>Maintainability</li><li>Portability</li></ul><p><br></p><h3 id="testing-of-software-structure-/-architecture-(structural-testing)">Testing of software structure / architecture (structural testing)</h3><p>Structural testing is most often used as a way of measuring the thoroughness of testing through the coverage of a set of structural elements or coverage items. It is also called <strong>white-box </strong>testing. Using <strong>code coverage</strong> could be useful here.</p><p><br></p><h3 id="testing-related-to-changes">Testing related to changes</h3><p>Testing related to changes can be subdivided into two types:</p><ul><li><strong>Confirmation testing: </strong>Test whether a defect is actually fixed (should be done in exactly the same way as to how the defect was originally discovered)</li><li><strong>Regression testing,:</strong> Execute previously succeeding test cases. Following modifications to ensure that defects have not been introduced in unchanged areas of the software as a result of the changes made. These tests are a prime candidate for automation.</li></ul><p><br></p><p><strong style="background-color: rgba(0, 0, 0, 0);">Modern iterative development</strong></p><ul><li><span style="background-color: transparent;">Continuous development is the norm.</span></li><li><span style="background-color: transparent;">Full automated test suite used as regression testing.</span></li><li><span style="background-color: transparent;">Test for specific changes act as confirmation tests.</span></li></ul><p><br></p><h2 id="v-model">V-model</h2><p>The v-model describes the life cycle of a software product. There are a variety of activities that are performed in parallel with development activities. This is visible in the v-model by the fact that test preparation isn't a single square, it's an ongoing process.</p><p><br></p><p><strong>Verification: </strong>making sure that you correctly implement the to be implemented specification. Do you get what you want?</p><p><strong>Validation: </strong>deciding if the software system meets the user's real needs. Do you get what you need?</p><p><br></p><p>On the left we see how we think of a system, by decomposing a system into small units</p><p><br></p><p><img src="https://i.imgur.com/Q1sPUsM.png" width="599"></p><p><em>Image taken from slides by Mauricio Aniche</em></p>