+++
title = "Introduction to Machine Learning"
date = 2019-09-10
+++
<h2 id="introduction">Introduction</h2><ul><li>Machine Learning aims to identify regularities in the world (or data), learning == training on data</li><li><strong>Generalization </strong>is coming to general conclusions from a limited number of specified observations</li><li>ML is having the ability to make decisions based on previous knowledge</li><li>Using data you try to create a function that separates classes, which is as pure as possible. Using this function you can draw a decision border.</li><li>There are two types of machine learning: supervised learning and unsupervised learning</li><li class="ql-indent-1"><strong>Supervised learning</strong>: there is a dataset with a label for each piece of data</li><li class="ql-indent-1"><strong>Unsupervised learning</strong>: the system itself learns features about the data by itself. An example of unsupervised learning is dividing data into clusters.</li></ul><p><br></p><h2 id="aspects-of-machine-learning">Aspects of machine learning</h2><h3 id="general-pipeline">General pipeline</h3><ol><li>Train the ML algorithm using a dataset of examples with features for a specific task</li><li>Test the generalisability of the ML algorithm on an unseen testset.</li><li>Quantify performance using an accurate and suitable measurement</li></ol><p><br></p><p>The ML pipeline is visualized here:</p><p><img src="https://i.imgur.com/qezOQp4.png" width="442"></p><p><em>Image taken from slides by Odette Scharenborg</em></p><p><br></p><h3 id="the-task-﻿ttt﻿-">The task <span class="ql-formula" data-value="T">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span style="margin-right: 0.13889em;" class="mord mathdefault">T</span></span></span></span></span>﻿</span> </h3><p>ML enables us to tackle tasks that are too difficult to solve with fixed programs. Learning is the means through which we attain the <strong>ability </strong>to perform the task.</p><p><br></p><p>There are different types of tasks:</p><ul><li><strong>Classification</strong>: predicting a label, specify which of <span class="ql-formula" data-value="k">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span style="margin-right: 0.03148em;" class="mord mathdefault">k</span></span></span></span></span>﻿</span> categories some inputs belong to</li><li><strong>Regression: </strong>predicting a numerical value</li><li><strong>Anomaly detection: </strong>detecting events that are off</li><li><strong>Machine translation: </strong>convert symbols in one language to symbols into another language</li><li><strong>Transcription: </strong>building a model that is able to transcribe some kind of data into a discrete textual form</li></ul><p><br></p><h3 id="the-performance-measure-﻿ppp﻿-">The performance measure <span class="ql-formula" data-value="P">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span style="margin-right: 0.13889em;" class="mord mathdefault">P</span></span></span></span></span>﻿</span> </h3><p>The abilities of a ML algorithm is evaluated quantitatively.</p><p><br></p><p>The way we evaluate <span class="ql-formula" data-value="P">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span style="margin-right: 0.13889em;" class="mord mathdefault">P</span></span></span></span></span>﻿</span> depends on <span class="ql-formula" data-value="T">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span style="margin-right: 0.13889em;" class="mord mathdefault">T</span></span></span></span></span>﻿</span>. For example, for classification we use the accuracy/error rate, i.e. the proportion of correct/incorrect outputs by the model</p><p><br></p><p><span class="ql-formula" data-value="P">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span style="margin-right: 0.13889em;" class="mord mathdefault">P</span></span></span></span></span>﻿</span> is measured on unseen test data that:</p><ul><li>is similar to the training data</li><li>has not been used during training the algorithm</li><li>is used to test the generalization</li></ul><p><br></p><h3 id="the-experience-﻿eee﻿-">The experience <span class="ql-formula" data-value="E">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span style="margin-right: 0.05764em;" class="mord mathdefault">E</span></span></span></span></span>﻿</span> </h3><p>The experience is the dataset to train the ML algorithm. This determines whether a ML algorithm is supervised or unsupervised.</p><p><br></p><p>This dataset is often in the form of a design matrix, where every row is an example and the columns are features. One column will be the label.</p><p><br></p><h2 id="supervised-learning">Supervised learning</h2><p>In supervised learning, the machine learns the association between example (input) and label (output) by identifying patterns in the data. </p><p><br></p><p>The goal of training is learning a function that can predict a label <span class="ql-formula" data-value="y">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span style="margin-right: 0.03588em;" class="mord mathdefault">y</span></span></span></span></span>﻿</span> for a new <span class="ql-formula" data-value="x">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault">x</span></span></span></span></span>﻿</span> with as little error as possible. That is: new data that is independent but identically distributed should be handled as best as possible.</p><p><br></p><h3 id="linear-regression">Linear regression</h3><p>An example of this is linear regression</p><ul><li>Task <span class="ql-formula" data-value="T">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span style="margin-right: 0.13889em;" class="mord mathdefault">T</span></span></span></span></span>﻿</span>: take the general function <span class="ql-formula" data-value="y=ax+b">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><mi>a</mi><mi>x</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">y=ax+b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span style="margin-right: 0.03588em;" class="mord mathdefault">y</span><span class="mspace" style="margin-right: 0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height: 0.66666em; vertical-align: -0.08333em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault">b</span></span></span></span></span>﻿</span> and let <span class="ql-formula" data-value="\hat{y}">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8888799999999999em; vertical-align: -0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.69444em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span style="margin-right: 0.03588em;" class="mord mathdefault">y</span></span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.19444em;"><span class=""></span></span></span></span></span></span></span></span></span>﻿</span> be the value that the model predicts <span class="ql-formula" data-value="y">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span style="margin-right: 0.03588em;" class="mord mathdefault">y</span></span></span></span></span>﻿</span> should take. Then we get <span class="ql-formula" data-value="\hat{y}">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8888799999999999em; vertical-align: -0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.69444em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span style="margin-right: 0.03588em;" class="mord mathdefault">y</span></span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.19444em;"><span class=""></span></span></span></span></span></span></span></span></span>﻿</span><span class="ql-formula" data-value="=w^Tx+b">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>=</mo><msup><mi>w</mi><mi>T</mi></msup><mi>x</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">=w^Tx+b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.36687em; vertical-align: 0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height: 0.924661em; vertical-align: -0.08333em;"></span><span class="mord"><span style="margin-right: 0.02691em;" class="mord mathdefault">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8413309999999999em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span style="margin-right: 0.13889em;" class="mord mathdefault mtight">T</span></span></span></span></span></span></span></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault">b</span></span></span></span></span>﻿</span> where <span class="ql-formula" data-value="w">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span style="margin-right: 0.02691em;" class="mord mathdefault">w</span></span></span></span></span>﻿</span> is a set of weights that determines how each features influences the prediction (so how important a certain feature is)</li><li>Performance <span class="ql-formula" data-value="P">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span style="margin-right: 0.13889em;" class="mord mathdefault">P</span></span></span></span></span>﻿</span>: we can use the mean squared error, it should be as low as possible, this is the cost/loss function, which should be minimized. During training it will be iteratively improved, up to a certain point. This is called <strong>gradient descent.</strong></li></ul><p><br></p><h3 id="performance">Performance</h3><p>There are 2 key factors that determine the quality of <span class="ql-formula" data-value="P">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span style="margin-right: 0.13889em;" class="mord mathdefault">P</span></span></span></span></span>﻿</span>:</p><ul><li>The training error (if this is too big, you get <strong>underfitting</strong>)</li><li>The gap between training and test error (if this is too big you get <strong>overfitting</strong>)</li></ul><p><img src="https://i.imgur.com/xljFXgV.png" width="429"></p><p><em>Image taken from slides by Odette Scharenborg</em></p><p><br></p><p>In general you want to find the simplest model with the lowest training error. The complexity of a model is called the <strong>capacity.</strong></p><p><br></p><p><strong>No free lunch: </strong></p><p>Algorithms are designed for a specific task.</p><p>Averaged over all possible data-generating distributions, every classification algorithm has the same error rate when classifying previously unobserved points.</p><p>So in some sense, no machine learning algorithm is universally better than others, but some algorithms are better on the kinds of data-generating functions that we care about.</p>