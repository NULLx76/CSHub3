+++
title = "Recap"
date = 2019-10-22
+++
<p><img src="https://i.imgur.com/D30Bm3Y.png" width="726"></p><p><img src="https://i.imgur.com/hgVxMBy.png" width="598"></p><p>Knn^, as it's not linear</p><p><br></p><p><img src="https://i.imgur.com/E1R5PsS.png" width="570"></p><p>Probably linear</p><p><br></p><h2 id="what-classifier-to-use?">What classifier to use?</h2><p>If you cannot visualize high-dimensional data, how to choose? We need some criterion, typically classification performance/error.</p><p><br></p><p>This test is dependent on independent data. But what if we get the same error? For now we assume that classification error is good enough.</p><p><br></p><p>The classification error of the training set is a good measure of the true classification error? True, unless it is very bad</p><p>A good estimate of the actual, true, error is all we are after? False, often you want weighted classification errors</p><p><br></p><h2 id="k-fold-cross-validation">K fold cross validation</h2><p>Divide the dataset in groups of <span class="ql-formula" data-value="k">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span style="margin-right: 0.03148em;" class="mord mathdefault">k</span></span></span></span></span>﻿</span> samples. Use <span class="ql-formula" data-value="1">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">1</span></span></span></span></span>﻿</span> sample for testing, <span class="ql-formula" data-value="k-1">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.77777em; vertical-align: -0.08333em;"></span><span style="margin-right: 0.03148em;" class="mord mathdefault">k</span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">1</span></span></span></span></span>﻿</span> for training. Each time you train and test your error, then you repeat this until you have tested on all <span class="ql-formula" data-value="k">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span style="margin-right: 0.03148em;" class="mord mathdefault">k</span></span></span></span></span>﻿</span> groups. Then use the average error as the error for your classifier.</p><p><br></p><h2 id="double-cross-validation">Double cross validation</h2><p>You shouldn't optimize the parameters of the learning methods by looking at the test set.</p><p><br></p><p>You should optimize them by using cross-validation inside another cross-validation. It is possible that the different folds yield different parameters, so you can just average them.</p><p><br></p>