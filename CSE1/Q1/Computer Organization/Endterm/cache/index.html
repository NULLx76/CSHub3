<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>MyBlog</title>
  <link rel="stylesheet" href="https://nullx76.github.io/CSHub3/main.css">
</head>

<body>
  <div class="container">
    <head>
      <h1><a href="/">CSHub.nl</a></h1>
    </head>
    <section class="section">
      
  <section class="page">
  <h2><span>Cache</span></h2><ul><li><strong style="background-color: transparent;">Cache</strong><span style="background-color: transparent;">: storing a part of the memory inside a much faster cache, thus allowing for greater performance because less memory accesses are required</span></li><li class="ql-indent-1"><strong style="background-color: transparent;">READ </strong><span style="background-color: transparent;">operation</span></li><li class="ql-indent-2"><span style="background-color: transparent;">If not in cache (MISS), copy block into cache and read out of cache</span></li><li class="ql-indent-2"><span style="background-color: transparent;">If in cache (HIT), read out of cache</span></li></ul><p><br></p><ul><li class="ql-indent-1"><strong style="background-color: transparent;">WRITE </strong><span style="background-color: transparent;">operation</span></li><li class="ql-indent-2"><span style="background-color: transparent;">If not in cache (MISS), write in main memory</span></li><li class="ql-indent-2"><span style="background-color: transparent;">If in cache (HIT), write in cache, and either:</span></li><li class="ql-indent-3"><span style="background-color: transparent;">Write in main memory (store through)</span></li><li class="ql-indent-3"><span style="background-color: transparent;">Set modified (dirty) bit, and write later</span></li></ul><p><br></p><ul><li class="ql-indent-1"><span style="background-color: transparent;">Locality of reference:</span></li><li class="ql-indent-2"><span style="background-color: transparent;">Spatial locality (we use data that is close to each other, eg arrays)</span></li><li class="ql-indent-2"><span style="background-color: transparent;">Temporal locality (we use the data that we have used before, eg </span><strong style="background-color: transparent;">queue.ewi.tudelft.nl</strong><span style="background-color: transparent;">, TAs read the same requests)</span></li></ul><p><br></p><ul><li class="ql-indent-1"><span style="background-color: transparent;">Performance model for L1 cache: </span><em style="background-color: transparent;">access time cache * cache hit ratio + memory access time (1 - cache hit ratio)</em></li></ul><p><br></p><ul><li><strong style="background-color: transparent;">Cache organization</strong><span style="background-color: transparent;">:</span></li><li class="ql-indent-1"><span style="background-color: transparent;">Storage to hold: Data and Administration (in/out, clean/dirty)</span></li></ul><p><br></p><ul><li class="ql-indent-1"><span style="background-color: transparent;">Block based: Amortize admin overhead, efficient lookup (hit or miss), efficient memory access</span></li></ul><p><br></p><ul><li class="ql-indent-1"><span style="background-color: transparent;">How the cache works:</span></li><li class="ql-indent-2"><span style="background-color: transparent;">Access word </span><em style="background-color: transparent;">w</em><span style="background-color: transparent;"> in memory block </span><em style="background-color: transparent;">B</em></li><li class="ql-indent-2"><span style="background-color: transparent;">Is block </span><em style="background-color: transparent;">B</em><span style="background-color: transparent;"> in the cache?</span></li><li class="ql-indent-2"><span style="background-color: transparent;">If not, </span><strong style="background-color: transparent;">MISS</strong></li><li class="ql-indent-3"><span style="background-color: transparent;">Get block </span><em style="background-color: transparent;">B</em><span style="background-color: transparent;"> from memory</span></li><li class="ql-indent-3"><span style="background-color: transparent;">Calculate where to place it in the cache</span></li><li class="ql-indent-3"><span style="background-color: transparent;">Is position free?</span></li><li class="ql-indent-3"><span style="background-color: transparent;">If not, evict block at </span><em style="background-color: transparent;">B</em><span style="background-color: transparent;">’s place from the cache</span></li><li class="ql-indent-3"><span style="background-color: transparent;">Write </span><em style="background-color: transparent;">B</em><span style="background-color: transparent;"> to its cache location</span></li><li class="ql-indent-2"><span style="background-color: transparent;">Access </span><em style="background-color: transparent;">w</em><span style="background-color: transparent;"> in the cache</span></li></ul><p><br></p><ul><li><a href="https://en.wikipedia.org/wiki/Cache_Placement_Policies" target="_blank" style="background-color: transparent;"><strong>Where to place blocks</strong></a><strong style="background-color: transparent;">:</strong></li><li class="ql-indent-1"><strong>Direct mapped cache</strong><span>: the cache is organized into multiple sets, with a tag being saved per tag. There can only be one cache entry per set. It is not flexible (as there can only be 1 element per set, meaning that if this set is often used, a lot of data is kicked out), but easy to look up blocks in the cache</span></li></ul><p><br></p><ul><li class="ql-indent-1"><strong style="background-color: transparent;">(Fully) associative cache</strong><span style="background-color: transparent;">: only the tag is stored, on one big pile of tags. It is more difficult to lookup blocks, we need to check all the labels (can be done in parallel). But it is very flexible, higher hit radio, as block can be anywhere in the cache.</span></li></ul><p><br></p><ul><li class="ql-indent-1"><strong style="background-color: transparent;">Set associative cache</strong><span style="background-color: transparent;">: a combination of the above mentioned techniques; multiple blocks can be in a single set, on the tag of which you can search. So there is more flexibility than in direct mapped cache, as more blocks fit in a set, and also more speed than in fully-associative cache, as blocks are organized.</span></li><li class="ql-indent-2"><span style="background-color: transparent;">How many bits are needed for the following 'selectors':</span></li><li class="ql-indent-3"><strong>Word</strong><span>: the amount of bits needed to select a single word within a block</span></li><li class="ql-indent-3"><strong>Set: </strong><span>the amount of bits needed to select a single set in cache</span></li><li class="ql-indent-3"><strong>Tag: </strong><span>the amount of blocks in total possible memory - the set bits (the amount of bits needed to select the set)</span></li></ul><p><br></p><ul><li><strong style="background-color: transparent;">Cache replacement algorithms</strong><span style="background-color: transparent;">: what to do when the cache is full</span></li><li class="ql-indent-1"><span style="background-color: transparent;">Least recently used (LRU): keeps “time stamps” of accesses in counters, <span class="ql-formula" data-value="2^x">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mn>2</mn><mi>x</mi></msup></mrow><annotation encoding="application/x-tex">2^x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.664392em; vertical-align: 0em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.664392em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span></span></span></span></span></span></span></span></span>﻿</span>-way associative → <span class="ql-formula" data-value="x">﻿<span contenteditable="false"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault">x</span></span></span></span></span>﻿</span>-bit age counter per block</span></li></ul><p><br></p><ul><li class="ql-indent-1"><span style="background-color: transparent;">Algorithm:</span></li><li class="ql-indent-2"><span style="background-color: transparent;">Hit: reset counter of the block and increment the counters of the other blocks</span></li><li class="ql-indent-2"><span style="background-color: transparent;">Miss, set full: replace block with highest counter, reset this counter and increment the counters of the other blocks </span></li><li class="ql-indent-2"><span style="background-color: transparent;">Miss, set not full: place in empty spot and increment the counters of the other blocks</span></li></ul><p><br></p><ul><li class="ql-indent-1"><span style="background-color: transparent;">LRU alternatives:</span></li><li class="ql-indent-2"><span style="background-color: transparent;">Replace oldest block, First-In-First-Out (FIFO)</span></li><li class="ql-indent-2"><span style="background-color: transparent;">Least-Frequently Used (LFU)</span></li><li class="ql-indent-2"><span style="background-color: transparent;">Random replacement (fairs quite well)</span></li></ul><p><br></p><ul><li><strong style="background-color: transparent;">Cache coherence: </strong><span style="background-color: transparent;">when multi-threading, every processor might have its own cache, so it's possible for data to exist on multiple processors. This can be handled a couple different ways</span></li><li class="ql-indent-1"><strong style="background-color: transparent;">Write-through protocol: </strong><span style="background-color: transparent;">a processor updates its own cache and also the memory containing the cached block. All the other copies that exist will also be updated by a broadcast. Another possibility is invalidating the rest of the caches through a broadcast request (invalidating instead of updating)</span></li></ul><p><br></p><ul><li class="ql-indent-1"><strong style="background-color: transparent;">Write-back protocol: </strong><span style="background-color: transparent;">For a processor te be able to write to a block in its cache, it must become the only owner of this block. So all the other copies will be invalidated. Then when another processor wishes to read this block (which is invalidated in its own copy) a request is sent to the current owner which will send the requesting processor the data, and then also to the memory. Then memory takes ownership again.</span></li></ul><p><br></p><ul><li class="ql-indent-1"><strong style="background-color: transparent;">Snoopy caches: </strong><span style="background-color: transparent;">All broadcasts are done over a bus, one processor can look at this data and snoops all transactions on this bus and then update its own version of the cached block. There are multiple things that happen, but the gist is that the ability of cache controllers to observe actions on the bus and handle accordingly is called snoopy-caching.</span></li></ul><p><br></p><p><br></p>
  </section>

    </section>
  </div>
</body>

</html>